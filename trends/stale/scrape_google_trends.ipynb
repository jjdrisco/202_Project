{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "\n",
    "# Import scraping\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "# for question answering\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install curl_cffi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import curl_cffi for TLS fingerprint impersonation\n",
    "from curl_cffi import requests\n",
    "#from curl_cffi.impersonate import ImpersonateConfig\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrape Popularity Data from Google Trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOWNLOADS_FOLDER_FP = \"/Users/***REMOVED***/Downloads/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_file(file_path):\n",
    "    \"\"\"Delete a file from the specified path\"\"\"\n",
    "    try:\n",
    "        # Check if the file exists\n",
    "        if os.path.exists(file_path):\n",
    "            # Delete the file\n",
    "            os.remove(file_path)\n",
    "            print(f\"Successfully deleted: {file_path}\")\n",
    "        else:\n",
    "            print(f\"File not found: {file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error deleting file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_page_with_curl_impersonate(url, browser=\"chrome110\"):\n",
    "    \"\"\"\n",
    "    Fetch a page using curl_cffi with browser impersonation\n",
    "    \"\"\"\n",
    "    #config = ImpersonateConfig(browser)\n",
    "    session = requests.Session(impersonate=browser)\n",
    "    \n",
    "    # Add headers to better impersonate the browser\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/110.0.0.0 Safari/537.36\",\n",
    "        \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8\",\n",
    "        \"Accept-Language\": \"en-US,en;q=0.5\",\n",
    "        \"Accept-Encoding\": \"gzip, deflate, br\",\n",
    "        \"Connection\": \"keep-alive\",\n",
    "        \"Upgrade-Insecure-Requests\": \"1\",\n",
    "        \"Sec-Fetch-Dest\": \"document\",\n",
    "        \"Sec-Fetch-Mode\": \"navigate\",\n",
    "        \"Sec-Fetch-Site\": \"none\",\n",
    "        \"Sec-Fetch-User\": \"?1\",\n",
    "    }\n",
    "    \n",
    "    response = session.get(url, headers=headers)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "YOUR_USERNAME = \"***REMOVED***\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure Chrome options with your profile\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--user-data-dir=C:\\\\Users\\\\{YOUR_USERNAME}\\\\AppData\\\\Local\\\\Google\\\\Chrome\\\\User Data\")  # Update path\n",
    "chrome_options.add_argument(\"--profile-directory=Default\")  # Update with your profile name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error sending stats to Plausible: error sending request for url (https://plausible.io/api/event)\n"
     ]
    }
   ],
   "source": [
    "# Initialize Chrome with your profile\n",
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "\n",
    "# Optional: If you want to run in headless mode (no browser window)\n",
    "# from selenium.webdriver.chrome.options import Options\n",
    "# options = Options()\n",
    "# options.add_argument(\"--headless\")\n",
    "# driver = webdriver.Chrome(options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Artist/Artwork/Movement/Style/Location to search for\n",
    "entity_type = \"Location\"\n",
    "entity_name = \"The Getty\"\n",
    "entity_id = 1234"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading search activity data for 'Vincent van Gogh'...\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "\n",
    "    # Open the Google Trends homepage\n",
    "    url = \"https://trends.google.com/trends/explore\"\n",
    "    response = get_page_with_curl_impersonate(url)\n",
    "    #driver.post(url)\n",
    "    \n",
    "    # Save the response to a temporary HTML file\n",
    "    with open(\"trends_page.html\", \"wb\") as f:\n",
    "        f.write(response.content)\n",
    "    \n",
    "    # Let Selenium load the saved HTML to maintain the curl impersonation\n",
    "    # but still use Selenium for interaction\n",
    "    driver.get(\"file://\" + os.path.abspath(\"trends_page.html\"))\n",
    "    \n",
    "    # For subsequent navigation, we'll use a hybrid approach\n",
    "    # Now proceed with the normal Selenium interaction\n",
    "    wait = WebDriverWait(driver, 10)\n",
    "    \n",
    "    # Navigate to the actual URL after impersonation prep\n",
    "    driver.get(url)\n",
    "    \n",
    "    # Wait for the page to load and the search input to be available\n",
    "    search_input = wait.until(EC.element_to_be_clickable((By.ID, \"input-29\")))\n",
    "    \n",
    "    # Enter the artist name\n",
    "    search_input.send_keys(entity_name)\n",
    "    \n",
    "    # Small delay to allow autocomplete suggestions to appear\n",
    "    time.sleep(2)\n",
    "    \n",
    "    # Wait for autocomplete suggestions and click the second option\n",
    "    suggestions = wait.until(EC.presence_of_all_elements_located(\n",
    "        (By.CSS_SELECTOR, \"md-virtual-repeat-container md-autocomplete-parent-scope\")\n",
    "    ))\n",
    "    \n",
    "    # Click the second suggestion if available\n",
    "    if len(suggestions) >= 2:\n",
    "        suggestions[1].click()\n",
    "    else:\n",
    "        # Fallback: press Enter to search with the entered text\n",
    "        search_input.send_keys(Keys.RETURN)\n",
    "    \n",
    "    # Wait for the search results to load\n",
    "    time.sleep(5)\n",
    "    \n",
    "    # Find and click the \"Export\" button\n",
    "    export_button = wait.until(EC.element_to_be_clickable(\n",
    "        (By.CSS_SELECTOR, \"button.widget-actions-item.export\")\n",
    "    ))\n",
    "    export_button.click()\n",
    "    \n",
    "    # Wait for the file to download\n",
    "    print(f\"Downloading search activity data for '{entity_name}'...\")\n",
    "    time.sleep(10)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while accessing google trends: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Scraped Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pulled Trend Data for Vincent van Gogh: (Worldwide)\n",
      "Search activity data for 'The Getty':\n",
      "         Week  Vincent van Gogh: (Worldwide)\n",
      "0  2024-03-17                             84\n",
      "1  2024-03-24                             90\n",
      "2  2024-03-31                             87\n",
      "3  2024-04-07                             85\n",
      "4  2024-04-14                             85\n",
      "5  2024-04-21                            100\n",
      "6  2024-04-28                             81\n",
      "7  2024-05-05                             77\n",
      "8  2024-05-12                             83\n",
      "9  2024-05-19                             78\n",
      "10 2024-05-26                             78\n",
      "11 2024-06-02                             69\n",
      "12 2024-06-09                             66\n",
      "13 2024-06-16                             67\n",
      "14 2024-06-23                             64\n",
      "15 2024-06-30                             63\n",
      "16 2024-07-07                             66\n",
      "17 2024-07-14                             79\n",
      "18 2024-07-21                             69\n",
      "19 2024-07-28                             67\n",
      "20 2024-08-04                             71\n",
      "21 2024-08-11                             76\n",
      "22 2024-08-18                             79\n",
      "23 2024-08-25                             77\n",
      "24 2024-09-01                             74\n",
      "25 2024-09-08                             83\n",
      "26 2024-09-15                             84\n",
      "27 2024-09-22                             88\n",
      "28 2024-09-29                             78\n",
      "29 2024-10-06                             82\n",
      "30 2024-10-13                             79\n",
      "31 2024-10-20                             77\n",
      "32 2024-10-27                             73\n",
      "33 2024-11-03                             76\n",
      "34 2024-11-10                             81\n",
      "35 2024-11-17                             84\n",
      "36 2024-11-24                             73\n",
      "37 2024-12-01                             71\n",
      "38 2024-12-08                             71\n",
      "39 2024-12-15                             69\n",
      "40 2024-12-22                             70\n",
      "41 2024-12-29                             69\n",
      "42 2025-01-05                             77\n",
      "43 2025-01-12                             74\n",
      "44 2025-01-19                             75\n",
      "45 2025-01-26                             87\n",
      "46 2025-02-02                             78\n",
      "47 2025-02-09                             73\n",
      "48 2025-02-16                             73\n",
      "49 2025-02-23                             77\n",
      "50 2025-03-02                             74\n",
      "51 2025-03-09                             75\n",
      "52 2025-03-16                             80\n"
     ]
    }
   ],
   "source": [
    "# Load the CSV into a Pandas DataFrame\n",
    "download_path = DOWNLOADS_FOLDER_FP  # Update with your downloads path\n",
    "csv_file = f\"{download_path}/multiTimeline.csv\"\n",
    "df = pd.read_csv(csv_file, skiprows=2, parse_dates=['Week'])\n",
    "#delete_file(csv_file)\n",
    "\n",
    "# Sanity check on data\n",
    "print(\"Pulled Trend Data for \"+df.columns[1])\n",
    "\n",
    "# Display the DataFrame\n",
    "print(f\"Search activity data for '{entity_name}':\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_weeks = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(80.0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "today = datetime.now()\n",
    "one_week_ago = today - timedelta(weeks=n_weeks)\n",
    "popularity_last_week = np.mean(df[df['Week'] >= one_week_ago].iloc[:,1].values)\n",
    "popularity_last_week"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "^ this isn't popularity over all time, or a comparitve measure. this is how popular is this thing in {timeframe} compared to its own popularity all year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insert into Redis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting redis\n",
      "  Downloading redis-5.2.1-py3-none-any.whl.metadata (9.1 kB)\n",
      "Collecting async-timeout>=4.0.3 (from redis)\n",
      "  Downloading async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Downloading redis-5.2.1-py3-none-any.whl (261 kB)\n",
      "Downloading async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
      "Installing collected packages: async-timeout, redis\n",
      "Successfully installed async-timeout-5.0.1 redis-5.2.1\n"
     ]
    }
   ],
   "source": [
    "#! pip install redis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import redis\n",
    "import csv\n",
    "import json\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_to_redis(host='localhost', port=6379, db=0):\n",
    "    \"\"\"Connect to a Redis instance.\"\"\"\n",
    "    try:\n",
    "        redis_client = redis.Redis(host=host, port=port, db=db, decode_responses=True)\n",
    "        # Test the connection\n",
    "        redis_client.ping()\n",
    "        print(\"Successfully connected to Redis\")\n",
    "        return redis_client\n",
    "    except redis.ConnectionError as e:\n",
    "        print(f\"Failed to connect to Redis: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_trend_data_from_dataframe(df, entity_type, entity_id):\n",
    "    \"\"\"\n",
    "    Insert trend data from a pandas DataFrame into Redis.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: Pandas DataFrame with columns 'Week' and a data column\n",
    "    - entity_type: String, either 'artist' or 'artwork'\n",
    "    - name: String, the name of the entity (e.g., 'Vincent_van_Gogh')\n",
    "    \"\"\"\n",
    "    redis_client = connect_to_redis()\n",
    "    if not redis_client:\n",
    "        return\n",
    "    \n",
    "    # Create the key using the slug format\n",
    "    key = f\"trends:{entity_type}:{entity_id}\"\n",
    "    \n",
    "    # Check if DataFrame is not empty\n",
    "    if df.empty:\n",
    "        print(\"DataFrame is empty. No data to insert.\")\n",
    "        return\n",
    "    \n",
    "    # Get column names\n",
    "    columns = df.columns\n",
    "    if len(columns) < 2 or 'Week' not in df.columns:\n",
    "        print(\"DataFrame must contain a 'Week' column and at least one data column.\")\n",
    "        return\n",
    "    \n",
    "    # Change week timestamp column back into date string for import\n",
    "    import_df = df.copy()\n",
    "    import_df['Week'] = import_df['Week'].dt.strftime('%Y-%m-%d')\n",
    "    \n",
    "    # Use pipeline for better performance when inserting multiple values\n",
    "    with redis_client.pipeline() as pipe:\n",
    "        # Insert each row of the DataFrame into Redis\n",
    "        for index, row in import_df.iterrows():\n",
    "            week_date = row['Week']\n",
    "            # Assuming the second column contains the trend value\n",
    "            trend_value = row[columns[1]] if columns[1] != 'Week' else row[columns[0]]\n",
    "            \n",
    "            # Store as hash entry\n",
    "            pipe.hset(key, week_date, int(trend_value))\n",
    "        \n",
    "        # Add metadata\n",
    "        pipe.hset(f\"{key}:meta\", \"type\", entity_type)\n",
    "        pipe.hset(f\"{key}:meta\", \"name\", entity_id)\n",
    "        pipe.hset(f\"{key}:meta\", \"last_updated\", datetime.now().isoformat())\n",
    "        \n",
    "        # Execute all commands in the pipeline\n",
    "        pipe.execute()\n",
    "    \n",
    "    # Force a save to ensure persistence\n",
    "    redis_client.save()\n",
    "    \n",
    "    print(f\"Successfully stored {len(df)} data points for {key}\")\n",
    "    print(\"Data has been persisted to disk\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#temp id for testing\n",
    "artist_id = 1234"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully connected to Redis\n",
      "Successfully stored 53 data points for trends:artist:1234\n",
      "Data has been persisted to disk\n",
      "Successfully connected to Redis\n",
      "Retrieved 53 data points for trends:artist:1234\n",
      "2024-03-17: 84\n",
      "2024-03-24: 90\n",
      "2024-03-31: 87\n",
      "2024-04-07: 85\n",
      "2024-04-14: 85\n"
     ]
    }
   ],
   "source": [
    "# Insert data into Redis\n",
    "entity_type = \"artist\"\n",
    "name = entity_id\n",
    "\n",
    "insert_trend_data_from_dataframe(df, entity_type, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully connected to Redis\n",
      "Retrieved 53 data points for trends:artist:1234\n",
      "2024-03-17: 84\n",
      "2024-03-24: 90\n",
      "2024-03-31: 87\n",
      "2024-04-07: 85\n",
      "2024-04-14: 85\n"
     ]
    }
   ],
   "source": [
    "# For retrieving the data\n",
    "redis_client = connect_to_redis()\n",
    "if redis_client:\n",
    "    key = f\"trends:{entity_type}:{name}\"\n",
    "    data = redis_client.hgetall(key)\n",
    "    print(f\"Retrieved {len(data)} data points for {key}\")\n",
    "    \n",
    "    # Optional: Print some sample data\n",
    "    sample_items = list(data.items())[:5]\n",
    "    for date, value in sample_items:\n",
    "        print(f\"{date}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Week          datetime64[ns]\n",
       "Popularity             int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert retrieved data to dataframe\n",
    "\n",
    "retreived_df = pd.DataFrame(data.items(), columns=['Week', 'Popularity'])\n",
    "#retreived_df['Week'] = retreived_df['Week'].to_timestamp()\n",
    "retreived_df['Week'] = pd.to_datetime(retreived_df['Week'])\n",
    "retreived_df['Popularity'] = pd.to_numeric(retreived_df['Popularity'])\n",
    "retreived_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(80.0)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test import worked\n",
    "today = datetime.now()\n",
    "one_week_ago = today - timedelta(weeks=n_weeks)\n",
    "popularity_last_week = np.mean(retreived_df[retreived_df['Week'] >= one_week_ago].iloc[:,1].values)\n",
    "popularity_last_week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsc202project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
