{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! conda install psycopg2 -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! conda install tqdm -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! conda install regex -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import psycopg2\n",
    "from tqdm import tqdm\n",
    "import regex as re\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine Data Sources\n",
    "\n",
    "Can skip this section and load combined file below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "moma_artists = pd.read_csv('data/Artists.csv')\n",
    "moma_artworks = pd.read_csv('data/Artworks.csv')\n",
    "painter_palette = pd.read_csv('data/PainterPalette.csv')\n",
    "wikidata = pd.read_csv('data/Total_Merged_Painters_Data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean MOMA Artists dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure ConstituentID is unique\n",
    "moma_artists = moma_artists.drop_duplicates(subset=['ConstituentID'])\n",
    "\n",
    "# Extract birth and death years from ArtistBio. Fill missing values and convert data types.\n",
    "moma_artists['birth_year'] = moma_artists['ArtistBio'].str.extract(r'(\\d{4})‚Äì').astype(float).fillna(0).astype(int)\n",
    "moma_artists['death_year'] = moma_artists['ArtistBio'].str.extract(r'‚Äì(\\d{4})').astype(float).fillna(0).astype(int)\n",
    "moma_artists['Nationality'] = moma_artists['Nationality'].fillna('Unknown')\n",
    "moma_artists['Gender'] = moma_artists['Gender'].fillna('Unknown')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean MOMA Artworks dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure artwork is unique\n",
    "moma_artworks = moma_artworks.drop_duplicates(subset=['ObjectID'], keep='first')\n",
    "moma_artworks = moma_artworks.drop_duplicates(subset=['Title'])\n",
    "\n",
    "# Convert ConstituentID column to string, split, explode, and convert to integers\n",
    "moma_artworks['ConstituentID'] = moma_artworks['ConstituentID'].astype(str).str.split(', ')\n",
    "moma_artworks = moma_artworks.explode('ConstituentID')\n",
    "moma_artworks['ConstituentID'] = pd.to_numeric(moma_artworks['ConstituentID'], errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "# Filter out rows where ConstituentID is 0\n",
    "moma_artworks = moma_artworks[moma_artworks['ConstituentID'] != 0]\n",
    "\n",
    "# Extract start and end years from the date column\n",
    "moma_artworks['start_year'] = moma_artworks['Date'].str.extract(r'(\\d{4})').astype(float)  # Extract start year\n",
    "moma_artworks['end_year'] = moma_artworks['Date'].str.extract(r'-(\\d{2})').astype(float)  # Extract end year (last 2 digits)\n",
    "\n",
    "# Handle cases where the end year is only 2 digits (e.g., \"1976-77\")\n",
    "moma_artworks['start_year'] = moma_artworks['Date'].str.extract(r'(\\d{4})').astype(float).fillna(0).astype(int)\n",
    "moma_artworks['end_year'] = moma_artworks['Date'].str.extract(r'-(\\d{2})').astype(float)\n",
    "moma_artworks['end_year'] = (\n",
    "    moma_artworks['start_year'].astype(str).str[:2] + \n",
    "    moma_artworks['end_year'].astype(str).str.zfill(2)\n",
    ").fillna(moma_artworks['start_year'].astype(str))\n",
    "\n",
    "moma_artworks['start_year'] = pd.to_numeric(moma_artworks['start_year'], errors='coerce').fillna(0).astype(int)\n",
    "moma_artworks['end_year'] = pd.to_numeric(moma_artworks['end_year'], errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "moma_artworks['Artist'] = moma_artworks['Artist'].fillna('Unknown')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean PainterPalette dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean PainterPalette dataset\n",
    "columns_to_clean = [\n",
    "    'Nationality', 'citizenship', 'gender', 'styles', 'movement', 'birth_place', \n",
    "    'death_place', 'occupations', 'Influencedby', 'Influencedon', \n",
    "    'Pupils', 'Teachers', 'FriendsandCoworkers', 'Contemporary', 'PaintingSchool'\n",
    "]\n",
    "\n",
    "painter_palette[columns_to_clean] = painter_palette[columns_to_clean].fillna('Unknown')\n",
    "for col in ['styles', 'Nationality', 'Influencedby', 'Influencedon', 'Pupils', 'Teachers'\n",
    "            , 'FriendsandCoworkers', 'Contemporary', 'occupations']:\n",
    "    painter_palette[col] = painter_palette[col].str.split(',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean WikiData dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean WikiData dataset\n",
    "columns_to_clean = [\n",
    "    'Nationality', 'citizenship', 'gender', 'styles', 'movement', 'birth_place', \n",
    "    'death_place', 'occupations', 'Influencedby', 'Influencedon', \n",
    "    'Pupils', 'Teachers', 'FriendsandCoworkers', 'Contemporary', 'PaintingSchool'\n",
    "]\n",
    "\n",
    "wikidata[columns_to_clean] = wikidata[columns_to_clean].fillna('Unknown')\n",
    "for col in ['styles', 'Nationality', 'Influencedby', 'Influencedon', 'Pupils', 'Teachers'\n",
    "            , 'FriendsandCoworkers', 'Contemporary', 'occupations']:\n",
    "    wikidata[col] = wikidata[col].str.split(',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in PainterPalette with data from WikiData dataset\n",
    "\n",
    "artists_combined = pd.merge(\n",
    "    painter_palette, \n",
    "    wikidata, \n",
    "    left_on='artist', \n",
    "    right_on='artist_name', \n",
    "    how='left',\n",
    "    suffixes=('', '_wiki')\n",
    ")\n",
    "\n",
    "# List of columns to fill from the wikidata dataset\n",
    "columns_to_fill = ['Nationality', 'citizenship', 'gender', 'styles', 'movement', 'Art500k_Movements','birth_place', 'death_place', 'birth_year', 'death_year',\n",
    "                   'locations', 'FirstYear', 'LastYear', 'wikiart_pictures_count', 'styles_extended', 'locations_with_years', 'StylesCount', 'StylesYears', \n",
    "                   'occupations', 'PaintingsExhibitedAt', 'PaintingsExhibitedAtCount', 'PaintingSchool', 'Influencedby', 'Influencedon', 'Pupils', 'Teachers', \n",
    "                   'FriendsandCoworkers', 'Contemporary', 'Type']\n",
    "\n",
    "# Combine the columns to fill from both painter_palette and wikidata\n",
    "for col in columns_to_fill:\n",
    "    if col in artists_combined.columns and f'{col}_wiki' in artists_combined.columns:\n",
    "        # Fill missing values in the target column (from painter_palette) with the values from the wiki column\n",
    "        artists_combined[col] = artists_combined[col].combine_first(artists_combined[f'{col}_wiki'])\n",
    "    else:\n",
    "        print(f\"Warning: Column {col} or {col}_wiki not found in the merged dataset.\")\n",
    "\n",
    "# Drop the columns that were added from wikidata dataset to avoid duplication\n",
    "for col in columns_to_fill:\n",
    "    wiki_col = f'{col}_wiki'\n",
    "    if wiki_col in artists_combined.columns:\n",
    "        artists_combined.drop(columns=[wiki_col], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with MOMA Artists dataset\n",
    "artists_combined = pd.merge(\n",
    "    artists_combined, \n",
    "    moma_artists, \n",
    "    left_on='artist', \n",
    "    right_on='DisplayName', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "artists_combined['Nationality'] = artists_combined['Nationality_x']\n",
    "artists_combined = artists_combined.drop(columns=['Nationality_x', 'Nationality_y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with MOMA Artworks dataset\n",
    "artists_combined = pd.merge(\n",
    "    artists_combined, \n",
    "    moma_artworks, \n",
    "    left_on='artist', \n",
    "    right_on='Artist', \n",
    "    how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of columns to combine that have '_x' and '_y' versions\n",
    "columns_to_combine = ['birth_year', 'death_year', 'Nationality', 'Gender', 'ArtistBio', 'ConstituentID', 'BeginDate', 'EndDate']\n",
    "\n",
    "# Combine the '_x' and '_y' columns\n",
    "for col in columns_to_combine:\n",
    "    col_x = col + '_x'\n",
    "    col_y = col + '_y'\n",
    "    \n",
    "    # Ensure both columns exist in the dataframe\n",
    "    if col_x in artists_combined.columns and col_y in artists_combined.columns:\n",
    "        # Combine the columns (using _x values, and filling missing values from _y)\n",
    "        artists_combined[col] = artists_combined[col_x].combine_first(artists_combined[col_y])\n",
    "        \n",
    "        # Drop the original '_x' and '_y' columns after combining\n",
    "        artists_combined.drop(columns=[col_x, col_y], inplace=True)\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "artists_combined.head()\n",
    "\n",
    "artists_combined.to_csv('data/artists_combined.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Combined Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4y/wlpg0gj171v5rkdnqy7569k***REMOVED***0gn/T/ipykernel_14659/3002859731.py:1: DtypeWarning: Columns (5,9,10,13,14,15,26,28) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  artists_combined = pd.read_csv('data/artists_combined.csv')\n"
     ]
    }
   ],
   "source": [
    "artists_combined = pd.read_csv('data/artists_combined.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Postgres Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Connect To Postgres:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to Postgres\n",
    "conn = psycopg2.connect(\n",
    "    dbname=\"202Project\",\n",
    "    user=\"postgres\",\n",
    "    password=\"***REMOVED***\",\n",
    "    host=\"localhost\",\n",
    "    port=\"5432\"\n",
    ")\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Insert Artists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/60713 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 60713/60713 [01:02<00:00, 972.39it/s] \n"
     ]
    }
   ],
   "source": [
    "# Iterate through artists_combined and insert into Artists table\n",
    "for _, row in tqdm(artists_combined.iterrows(), total=artists_combined.shape[0]):\n",
    "\n",
    "    # Check and clean year columns to ensure valid ranges\n",
    "    birth_year = row.get('birth_year', None)\n",
    "    death_year = row.get('death_year', None)\n",
    "    career_start_year = row.get('FirstYear', None)\n",
    "    career_end_year = row.get('LastYear', None)\n",
    "\n",
    "    # Skip rows where year columns NaN or too large\n",
    "    if pd.isna(birth_year) or birth_year > 2030:\n",
    "        birth_year = None  # Skip this row\n",
    "\n",
    "    if pd.isna(death_year) or death_year > 2030:\n",
    "        death_year = None  # Skip this row\n",
    "\n",
    "    if pd.isna(career_start_year) or career_start_year > 2030:\n",
    "        career_start_year = None  # Skip this row\n",
    "\n",
    "    if pd.isna(career_end_year):\n",
    "        career_end_year = None  # Skip this row\n",
    "        \n",
    "    if type(career_end_year) == str:\n",
    "        if \"https\" in career_end_year:\n",
    "            career_end_year = None\n",
    "        else:\n",
    "            career_end_year = int(career_end_year.replace(\".0\", \"\"))\n",
    "    if (career_end_year is not None) and career_end_year > 2030:\n",
    "        career_end_year = None\n",
    "\n",
    "    # Convert to int\n",
    "    birth_year = int(birth_year) if birth_year is not None else None\n",
    "    birth_year = None if birth_year == 0 else birth_year\n",
    "\n",
    "    death_year = None if (death_year is not None) and death_year == 0 else death_year\n",
    "\n",
    "    career_start_year = None if (career_start_year is not None) and career_start_year == 0 else career_start_year\n",
    "\n",
    "    career_end_year = None if (career_end_year is not None) and career_end_year == 0 else career_end_year\n",
    "\n",
    "    artist_name = row['artist']\n",
    "\n",
    "    nationality = row.get('Nationality', None)\n",
    "    if re.match(r'Q\\d+', str(nationality)):\n",
    "        nationality = None\n",
    "    if nationality is not None:\n",
    "        nationality = str(nationality).strip(\"[\").strip(\"]\").replace(\"'\", \"\")\n",
    "    if 'unknown' in str(nationality).lower():\n",
    "        nationality = None\n",
    "    citizenship = row.get('citizenship', None)\n",
    "    if 'unknown' in str(citizenship).lower():\n",
    "        citizenship = None\n",
    "    gender = row.get('gender', None)\n",
    "    if 'unknown' in str(gender).lower():\n",
    "        gender = None\n",
    "\n",
    "    # Insert data into the Artists table\n",
    "    cursor.execute(\"\"\"\n",
    "        INSERT INTO Artists (\n",
    "            artist_name, birth_year, nationality, \n",
    "            citizenship, gender, death_year, career_start_year, career_end_year\n",
    "        )\n",
    "        VALUES (%s, %s, %s, %s, %s, %s, %s, %s)\n",
    "        ON CONFLICT (artist_name, birth_year_key) DO NOTHING;\n",
    "    \"\"\", (\n",
    "        artist_name, birth_year, nationality, \n",
    "        citizenship, gender, death_year, career_start_year, career_end_year\n",
    "    ))\n",
    "\n",
    "conn.commit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inserting Occupations & Occupations_Artists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing isolated occs: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1753/1753 [00:00<00:00, 69607.92it/s]\n",
      "inserting: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 986/986 [00:00<00:00, 2582.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Occupation Insertion Complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Extract the \"occupations\" column from artists_combined DataFrame\n",
    "occupations_data = artists_combined['occupations']\n",
    "\n",
    "# Create a set to store unique occupations\n",
    "unique_occupations = set()\n",
    "\n",
    "# Process each row in the occupations column\n",
    "for occupations in occupations_data:\n",
    "    if isinstance(occupations, str):  \n",
    "        # If it's a comma-separated string, split and strip spaces\n",
    "        unique_occupations.update([occ.strip() for occ in occupations.split(', ') if occ.strip()])\n",
    "    elif isinstance(occupations, list):  \n",
    "        # If it's a list, clean each element\n",
    "        unique_occupations.update([str(occ).strip() for occ in occupations if pd.notna(occ) and str(occ).strip()])\n",
    "    elif isinstance(occupations, np.ndarray):  \n",
    "        # Convert NumPy array to list and clean\n",
    "        if not pd.isna(occupations).all():  \n",
    "            unique_occupations.update([str(occ).strip() for occ in occupations.tolist() if pd.notna(occ) and str(occ).strip()])\n",
    "    elif pd.notna(occupations):  \n",
    "        # Handle any other non-null value\n",
    "        unique_occupations.add(str(occupations).strip())\n",
    "\n",
    "cleaner_occupations = set()\n",
    "# more processing yay!\n",
    "for occupation in tqdm(unique_occupations, desc=\"processing isolated occs\"):\n",
    "    occupation = occupation.replace(\"[\",\"\").replace(\"]\",\"\").replace(\"'\",\"\").replace(\"\\\"\",\"\")\n",
    "    if re.match(r'Q\\d+', occupation):\n",
    "        continue\n",
    "    cleaner_occupations.add(occupation)\n",
    "\n",
    "# Insert unique occupations into the Occupations table\n",
    "for occupation in tqdm(cleaner_occupations, desc=\"inserting\"):\n",
    "    try:\n",
    "        cursor.execute(\"\"\"\n",
    "            INSERT INTO Occupations (occupation_name)\n",
    "            VALUES (%s)\n",
    "            ON CONFLICT (occupation_name) DO NOTHING;\n",
    "        \"\"\", (occupation,))\n",
    "    except Exception as e:\n",
    "        print(f\"Error inserting occupation {occupation} -> {e}\")\n",
    "        conn.rollback()\n",
    "\n",
    "conn.commit()\n",
    "\n",
    "print(\"Occupation Insertion Complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fetched existing artists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iterating artists:   0%|          | 0/60713 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iterating artists: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 60713/60713 [00:04<00:00, 12781.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artist_Occupations Insertion Complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Fetch existing artists from the database before processing\n",
    "cursor.execute(\"SELECT artist_name FROM Artists;\")\n",
    "existing_artists = set(cursor.fetchall())  # Store as a set of tuples (artist_name, birth_year)\n",
    "print(\"fetched existing artists\")\n",
    "\n",
    "# Iterate over each row in the DataFrame\n",
    "for _, row in tqdm(artists_combined.iterrows(), total=artists_combined.shape[0], \n",
    "                   desc=\"iterating artists\"):\n",
    "    artist_name = row.get('artist', None)\n",
    "    birth_year = row.get('birth_year', None)\n",
    "\n",
    "    # Convert to int\n",
    "    birth_year = int(birth_year) if (not pd.isna(birth_year)) and (birth_year is not None) else None\n",
    "    birth_year = None if (pd.isna(birth_year)) or (birth_year == 0) or (birth_year > 2030) else birth_year\n",
    "\n",
    "    # Ensure the artist exists in Artists table before inserting occupations\n",
    "    if (artist_name) not in existing_artists:\n",
    "        continue  # Skip this row if artist doesn't exist in Artists table\n",
    "\n",
    "    # Extract occupations from row\n",
    "    occupations = row.get('occupations', None)\n",
    "    \n",
    "    # Create a set to store unique occupations\n",
    "    unique_occupations = set()\n",
    "\n",
    "    # Process each row in the occupations column\n",
    "    if isinstance(occupations, str):  \n",
    "        # If it's a comma-separated string, split and strip spaces\n",
    "        unique_occupations.update([occ.strip() for occ in occupations.split(', ') if occ.strip()])\n",
    "    elif isinstance(occupations, list):  \n",
    "        # If it's a list, clean each element\n",
    "        unique_occupations.update([str(occ).strip() for occ in occupations if pd.notna(occ) and str(occ).strip()])\n",
    "    elif isinstance(occupations, np.ndarray):  \n",
    "        # Convert NumPy array to list and clean\n",
    "        if not pd.isna(occupations).all():  \n",
    "            unique_occupations.update([str(occ).strip() for occ in occupations.tolist() if pd.notna(occ) and str(occ).strip()])\n",
    "    elif pd.notna(occupations):  \n",
    "        # Handle any other non-null value\n",
    "        unique_occupations.add(str(occupations).strip())\n",
    "\n",
    "    cleaner_occupations = set()\n",
    "    # more processing yay!\n",
    "    for occupation in unique_occupations:\n",
    "        occupation = occupation.replace(\"[\",\"\").replace(\"]\",\"\").replace(\"'\",\"\").replace(\"\\\"\",\"\")\n",
    "        if re.match(r'Q\\d+', occupation):\n",
    "            continue\n",
    "        cleaner_occupations.add(occupation)\n",
    "\n",
    "    # Insert valid occupations into the Artist_Occupations table\n",
    "    for occupation in cleaner_occupations:\n",
    "        try:\n",
    "            cursor.execute(\"\"\"\n",
    "                INSERT INTO Artist_Occupations (artist_name, birth_year, occupation_name)\n",
    "                VALUES (%s, %s, %s)\n",
    "                ON CONFLICT (artist_name, birth_year, occupation_name) DO NOTHING;\n",
    "            \"\"\", (artist_name, birth_year, occupation))\n",
    "        except Exception as e:\n",
    "            print(f\"Error inserting occupation for {artist_name}, {birth_year}: {occupation} -> {e}\")\n",
    "            conn.rollback()\n",
    "\n",
    "# Commit all changes after insertions\n",
    "conn.commit()\n",
    "\n",
    "print(\"Artist_Occupations Insertion Complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.isna(birth_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(birth_year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inserting Artworks, Additional Artists, Artists_Artworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 118807/118807 [00:12<00:00, 9874.07it/s] \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "import psycopg2.extras\n",
    "\n",
    "# üîπ **Step 1: Fetch Existing Artists**\n",
    "cursor.execute(\"SELECT artist_name, birth_year FROM Artists;\")\n",
    "existing_artists = set(cursor.fetchall())  # Store as a set of (artist_name, birth_year)\n",
    "\n",
    "# üîπ **Step 2: Prepare Data for Bulk Insert**\n",
    "artists_to_insert = []\n",
    "artworks_to_insert = []\n",
    "artists_artworks_to_insert = []\n",
    "\n",
    "for _, row in tqdm(moma_artworks.iterrows(), total=len(moma_artworks)):\n",
    "    title = row.get('Title', None)\n",
    "    artwork_date = row.get('Date', None)\n",
    "\n",
    "    # üîπ **Extract the first four-digit year from artwork_date**\n",
    "    artwork_date_match = re.search(r'\\d{4}', str(artwork_date)) if artwork_date else None\n",
    "    artwork_date = int(artwork_date_match.group(0)) if artwork_date_match else None\n",
    "\n",
    "    artists_info = {}\n",
    "\n",
    "    artist_name = row.get('Artist', None)\n",
    "    if (artist_name is not None) and (\",\" in artist_name):\n",
    "        artists_list = artist_name.split(\", \")\n",
    "        for i in range(len(artists_list)):\n",
    "            artists_info[i] = {}\n",
    "            artists_info[i]['artist_name'] = artists_list[i]\n",
    "    else:\n",
    "        artists_info[0] = {}\n",
    "        artists_info[0]['artist_name'] = artist_name\n",
    "\n",
    "    birth_year = row.get('BeginDate', None)\n",
    "    if (birth_year is not None) and (\" \" in birth_year):\n",
    "        birth_year_list = birth_year.replace(\"(\", \"\").replace(\")\", \"\").split(\" \")\n",
    "        for i in range(len(birth_year_list)):\n",
    "            birth_year_match = re.search(r'\\d{4}', str(birth_year_list[i])) if birth_year_list[i] else None\n",
    "            birth_year = int(birth_year_match.group(0)) if birth_year_match else None\n",
    "            artists_info[i]['birth_year'] = birth_year\n",
    "    elif (birth_year is not None):\n",
    "        birth_year_match = re.search(r'\\d{4}', str(birth_year))\n",
    "        birth_year = int(birth_year_match.group(0)) if birth_year_match else None\n",
    "        artists_info[0]['birth_year'] = birth_year\n",
    "\n",
    "\n",
    "    medium = row.get('Medium', None)\n",
    "    department = row.get('Department', None)\n",
    "    date_acquired = row.get('DateAcquired', None)\n",
    "    art_classification = row.get('Classification', None)\n",
    "    credit_line = row.get('CreditLine', None)\n",
    "\n",
    "    nationality = row.get('Nationality', None)\n",
    "    if \"unknown\" in str(nationality).lower():\n",
    "        nationality = None\n",
    "    elif (nationality is not None) and (\") (\" in nationality):\n",
    "        nationality_list = nationality.strip(\"(\").strip(\")\").split(\") (\")\n",
    "        for i in range(len(nationality_list)):\n",
    "            artists_info[i]['nationality'] = nationality_list[i]\n",
    "    elif (nationality is not None):\n",
    "        artists_info[0]['nationality'] = nationality.replace(\"(\", \"\").replace(\")\", \"\")\n",
    "\n",
    "    gender = row.get('Gender', None)\n",
    "    if (gender is not None) and (\") (\" in gender):\n",
    "        gender_list = gender.strip(\"(\").strip(\")\").split(\") (\")\n",
    "        for i in range(len(gender_list)):\n",
    "            artists_info[i]['gender'] = gender_list[i]\n",
    "    elif (gender is not None):\n",
    "        artists_info[0]['gender'] = gender.replace(\"(\", \"\").replace(\")\", \"\")\n",
    "\n",
    "    death_year = row.get('EndDate', None)\n",
    "    if (death_year is not None) and (\" \" in death_year):\n",
    "        death_year_list = death_year.replace(\"(\", \"\").replace(\")\", \"\").split(\" \")\n",
    "        for i in range(len(death_year_list)):\n",
    "            death_year_match = re.search(r'\\d{4}', str(death_year_list[i])) if death_year_list[i] else None\n",
    "            death_year = int(death_year_match.group(0)) if death_year_match else None\n",
    "            artists_info[i]['death_year'] = death_year\n",
    "    elif (death_year is not None):\n",
    "        death_year_match = re.search(r'\\d{4}', str(death_year)) if death_year else None\n",
    "        death_year = int(death_year_match.group(0)) if death_year_match else None\n",
    "        artists_info[0]['death_year'] = death_year\n",
    "\n",
    "\n",
    "    # üîπ **Check if the artist exists, otherwise add to insert list**\n",
    "    for i in range(len(artists_info)):\n",
    "        artist_name = artists_info[i].get('artist_name', None)\n",
    "        birth_year = artists_info[i].get('birth_year', None)\n",
    "\n",
    "        # Skip if artist_name or birth_year is missing\n",
    "        if (artist_name is None) or (birth_year is None):\n",
    "            continue\n",
    "\n",
    "        # Skip if artist_name and birth_year already exist in the database\n",
    "        if (artist_name, birth_year) not in existing_artists:\n",
    "\n",
    "            artists_to_insert.append((artist_name,\n",
    "                                      birth_year,\n",
    "                                      artists_info[i].get('nationality', None),\n",
    "                                      artists_info[i].get('gender', None), \n",
    "                                      artists_info[i].get('death_year', None)))\n",
    "            existing_artists.add((artist_name, birth_year))  # Add to cache to prevent duplicate inserts\n",
    "\n",
    "            artists_artworks_to_insert.append((artist_name, birth_year, title, artwork_date))\n",
    "\n",
    "    # üîπ **Prepare artwork insert data**\n",
    "    artworks_to_insert.append((title, artwork_date, medium, department, date_acquired, art_classification, credit_line))\n",
    "\n",
    "pd.DataFrame(artists_to_insert, columns=['artist_name', 'birth_year', 'nationality', 'gender', 'death_year']).to_csv(\"clean_and_import/artists_to_insert.csv\", index=False)\n",
    "pd.DataFrame(artworks_to_insert, columns=['title', 'artwork_date', 'medium', 'department', 'date_acquired', 'art_classification', 'credit_line']).to_csv(\"clean_and_import/artworks_to_insert.csv\", index=False)\n",
    "pd.DataFrame(artists_artworks_to_insert, columns=['artist_name', 'birth_year', 'title', 'artwork_date']).to_csv(\"clean_and_import/artists_artworks_to_insert.csv\", index=False)\n",
    "\n",
    "# # üîπ **Step 3: Batch Insert Artists**\n",
    "# if artists_to_insert:\n",
    "#     query = \"\"\"\n",
    "#         INSERT INTO Artists (artist_name, birth_year, nationality, gender, death_year)\n",
    "#         VALUES %s\n",
    "#         ON CONFLICT (artist_name, birth_year) DO NOTHING;\n",
    "#     \"\"\"\n",
    "#     psycopg2.extras.execute_values(cursor, query, artists_to_insert)\n",
    "#     print(f\"Inserted {len(artists_to_insert)} new artists.\")\n",
    "\n",
    "# # üîπ **Step 4: Batch Insert Artworks**\n",
    "# if artworks_to_insert:\n",
    "#     query = \"\"\"\n",
    "#         INSERT INTO Artworks (title, artwork_date, artist_name, birth_year, medium, department, date_acquired, art_classification, credit_line)\n",
    "#         VALUES %s\n",
    "#         ON CONFLICT (title, artwork_date) DO NOTHING;\n",
    "#     \"\"\"\n",
    "#     psycopg2.extras.execute_values(cursor, query, artworks_to_insert)\n",
    "#     print(f\"Inserted {len(artworks_to_insert)} artworks.\")\n",
    "\n",
    "# # üîπ **Step 5: Commit Changes**\n",
    "\n",
    "\n",
    "# print(\" Data Insertion Complete!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Important Note\n",
    "\n",
    "Use files \"artists_to_insert.csv\", \"artworks_to_insert.csv\", and \"artists_artworks_to_insert.csv\" to manually import data into tables using DataGrip.\n",
    "\n",
    "The complexity of psycopg2.extras.execute_values and regulary query execution calls are too high in python to run in a reasonable amount of time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Insert Artist Movement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting unique movements...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing movements: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 60713/60713 [00:00<00:00, 584311.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserting unique movements into the Movements table...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inserting movements: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 125/125 [00:00<00:00, 5440.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing artist-movement relationships...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing artists: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 60713/60713 [00:05<00:00, 11329.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserting artist-movement relationships...\n",
      "Successfully inserted 59705 artist-movement relationships\n",
      "Artist Movements Insertion Complete!\n"
     ]
    }
   ],
   "source": [
    "# First, extract unique movements and insert them into the Movements table (assuming it exists)\n",
    "movements_data = artists_combined['movement']\n",
    "\n",
    "# Create a set to store unique movements\n",
    "unique_movements = set()\n",
    "\n",
    "# Process each row in the movements column with tqdm progress bar\n",
    "print(\"Extracting unique movements...\")\n",
    "for movements in tqdm(movements_data, desc=\"Processing movements\"):\n",
    "    if isinstance(movements, str):  \n",
    "        # If it's a comma-separated string, split and strip spaces\n",
    "        unique_movements.update([mov.strip() for mov in movements.split(', ') if mov.strip()])\n",
    "    elif isinstance(movements, list):  \n",
    "        # If it's a list, clean each element\n",
    "        unique_movements.update([str(mov).strip() for mov in movements if pd.notna(mov) and str(mov).strip()])\n",
    "    elif isinstance(movements, np.ndarray):  \n",
    "        # Convert NumPy array to list and clean\n",
    "        if not pd.isna(movements).all():  \n",
    "            unique_movements.update([str(mov).strip() for mov in movements.tolist() if pd.notna(mov) and str(mov).strip()])\n",
    "    elif pd.notna(movements):  \n",
    "        # Handle any other non-null value\n",
    "        unique_movements.add(str(movements).strip())\n",
    "\n",
    "# Insert unique movements into the Movements table with tqdm progress bar\n",
    "print(\"Inserting unique movements into the Movements table...\")\n",
    "for movement in tqdm(unique_movements, desc=\"Inserting movements\"):\n",
    "    try:\n",
    "        cursor.execute(\"\"\"\n",
    "            INSERT INTO Movements (movement_name)\n",
    "            VALUES (%s)\n",
    "            ON CONFLICT (movement_name) DO NOTHING;\n",
    "        \"\"\", (movement,))\n",
    "    except Exception as e:\n",
    "        print(f\"Error inserting movement {movement} -> {e}\")\n",
    "        conn.rollback()\n",
    "\n",
    "# Now populate the Artist_Movements table\n",
    "artist_movements = []\n",
    "\n",
    "# Process the DataFrame to extract artist-movement relationships with years_active\n",
    "print(\"Processing artist-movement relationships...\")\n",
    "for index, row in tqdm(artists_combined.iterrows(), total=len(artists_combined), desc=\"Processing artists\"):\n",
    "    artist_name = row['artist_name']\n",
    "    birth_year = row['birth_year']\n",
    "\n",
    "    if pd.isna(birth_year) or birth_year > 2030:\n",
    "        continue  # Skip this row\n",
    "    # Convert to int\n",
    "    birth_year = int(birth_year)\n",
    "    birth_year = None if birth_year == 0 else birth_year\n",
    "    if birth_year is None:\n",
    "        continue\n",
    "    \n",
    "    \n",
    "    # Get movements for this artist\n",
    "    movements = []\n",
    "    \n",
    "    if isinstance(row['movement'], str):\n",
    "        movements = [mov.strip() for mov in row['movement'].split(', ') if mov.strip()]\n",
    "    elif isinstance(row['movement'], list):\n",
    "        movements = [str(mov).strip() for mov in row['movement'] if pd.notna(mov) and str(mov).strip()]\n",
    "    elif isinstance(row['movement'], np.ndarray):\n",
    "        movements = [str(mov).strip() for mov in row['movement'].tolist() if pd.notna(mov) and str(mov).strip()]\n",
    "    elif pd.notna(row['movement']):\n",
    "        movements = [str(row['movement']).strip()]\n",
    "\n",
    "    # Add to our list of relationships to insert\n",
    "    for movement in movements:\n",
    "        if movement is not None:\n",
    "            artist_movements.append({\n",
    "                'artist_name': artist_name,\n",
    "                'birth_year': birth_year,\n",
    "                'movement_name': movement\n",
    "            })\n",
    "\n",
    "# Insert the artist-movement relationships using executemany with psycopg2\n",
    "print(\"Inserting artist-movement relationships...\")\n",
    "try:\n",
    "    cursor.executemany(\"\"\"\n",
    "        INSERT INTO Artist_Movements (artist_name, birth_year, movement_name)\n",
    "        VALUES (%(artist_name)s, %(birth_year)s, %(movement_name)s)\n",
    "        ON CONFLICT (artist_name, birth_year, movement_name) DO NOTHING;\n",
    "    \"\"\", artist_movements)\n",
    "    conn.commit()\n",
    "    print(f\"Successfully inserted {len(artist_movements)} artist-movement relationships\")\n",
    "except Exception as e:\n",
    "    conn.rollback()\n",
    "    print(f\"Error batch inserting artist movements: {e}\")\n",
    "\n",
    "print(\"Artist Movements Insertion Complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Styles and Artist_Styles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract unique styles, flatten lists if necessary\n",
    "unique_styles = set()\n",
    "\n",
    "for styles in artists_combined['styles'].dropna():\n",
    "    if isinstance(styles, list):  # If stored as a list\n",
    "        unique_styles.update(style.strip() for style in styles)  # Remove extra spaces\n",
    "    else:\n",
    "        unique_styles.add(styles.strip())  # If single value, clean and add directly\n",
    "\n",
    "# Insert unique styles into the Styles table\n",
    "for style in unique_styles:\n",
    "    cursor.execute(\"\"\"\n",
    "        INSERT INTO Styles (style_name)\n",
    "        VALUES (%s)\n",
    "        ON CONFLICT (style_name) DO NOTHING;\n",
    "    \"\"\", (style,))\n",
    "\n",
    "# Commit the transaction\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through each row in the DataFrame\n",
    "for _, row in artists_combined.iterrows():\n",
    "    artist_name = row['artist']\n",
    "    birth_year = row['birth_year']\n",
    "\n",
    "    # Skip if birth_year is NaN, too large, or artist_name is missing\n",
    "    if pd.isna(artist_name) or pd.isna(birth_year) or birth_year > 2030:\n",
    "        continue\n",
    "\n",
    "    birth_year = int(birth_year)  # Convert birth_year to int\n",
    "    \n",
    "    # Process styles\n",
    "    styles = row['styles']\n",
    "    if isinstance(styles, str):  \n",
    "        styles = [s.strip() for s in styles.split(',')]\n",
    "    elif styles is None or (isinstance(styles, (list, pd.Series, pd.DataFrame)) and pd.isnull(styles).all()):  \n",
    "        continue  # Skip if styles are missing or empty\n",
    "\n",
    "    # Process StylesCount dictionary\n",
    "    styles_count = {}\n",
    "    if isinstance(row['StylesCount'], str):\n",
    "        for entry in row['StylesCount'].strip('{}').split(', '):\n",
    "            try:\n",
    "                style, count = entry.rsplit(':', 1)\n",
    "                styles_count[style.strip()] = int(count)\n",
    "            except ValueError:\n",
    "                continue  \n",
    "\n",
    "    # Process StylesYears dictionary\n",
    "    styles_years = {}\n",
    "    if isinstance(row['StylesYears'], str):\n",
    "        for entry in row['StylesYears'].split(','):\n",
    "            try:\n",
    "                style, years = entry.split(':', 1)\n",
    "                styles_years[style.strip()] = years.strip()\n",
    "            except ValueError:\n",
    "                continue  \n",
    "\n",
    "    # **Ensure artist exists in the Artists table**\n",
    "    cursor.execute(\"\"\"\n",
    "        INSERT INTO Artists (artist_name, birth_year)\n",
    "        VALUES (%s, %s)\n",
    "        ON CONFLICT (artist_name, birth_year) DO NOTHING;\n",
    "    \"\"\", (artist_name, birth_year))\n",
    "\n",
    "    # **Ensure styles exist in the Styles table**\n",
    "    for style in styles:\n",
    "        cursor.execute(\"\"\"\n",
    "            INSERT INTO Styles (style_name)\n",
    "            VALUES (%s)\n",
    "            ON CONFLICT (style_name) DO NOTHING;\n",
    "        \"\"\", (style,))\n",
    "\n",
    "    # Insert each style associated with the artist\n",
    "    for style in styles:\n",
    "        style_count = styles_count.get(style, None)\n",
    "        style_years = styles_years.get(style, None)\n",
    "\n",
    "        cursor.execute(\"\"\"\n",
    "            INSERT INTO Artist_Styles (artist_name, birth_year, style_name, style_count, style_years)\n",
    "            VALUES (%s, %s, %s, %s, %s)\n",
    "            ON CONFLICT (artist_name, birth_year, style_name) DO NOTHING;\n",
    "        \"\"\", (artist_name, birth_year, style, style_count, style_years))\n",
    "\n",
    "# Commit changes to the database\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Teacher Relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['artist', 'citizenship', 'gender', 'styles', 'movement',\n",
       "       'Art500k_Movements', 'birth_place', 'death_place', 'FirstYear',\n",
       "       'LastYear', 'wikiart_pictures_count', 'locations',\n",
       "       'locations_with_years', 'styles_extended', 'StylesCount', 'StylesYears',\n",
       "       'occupations', 'PaintingsExhibitedAt', 'PaintingsExhibitedAtCount',\n",
       "       'PaintingSchool', 'Influencedby', 'Influencedon', 'Pupils', 'Teachers',\n",
       "       'FriendsandCoworkers', 'Contemporary', 'Type', 'artist_name',\n",
       "       'Wikidata QID', 'DisplayName', 'Wiki QID', 'ULAN', 'Title', 'Artist',\n",
       "       'Date', 'Medium', 'Dimensions', 'CreditLine', 'AccessionNumber',\n",
       "       'Classification', 'Department', 'DateAcquired', 'Cataloged', 'ObjectID',\n",
       "       'URL', 'ImageURL', 'OnView', 'Circumference (cm)', 'Depth (cm)',\n",
       "       'Diameter (cm)', 'Height (cm)', 'Length (cm)', 'Weight (kg)',\n",
       "       'Width (cm)', 'Seat Height (cm)', 'Duration (sec.)', 'start_year',\n",
       "       'end_year', 'birth_year', 'death_year', 'Nationality', 'Gender',\n",
       "       'ArtistBio', 'ConstituentID', 'BeginDate', 'EndDate'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artists_combined.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10                 ['The cycle of 5 paintings Deluge', '']\n",
       "40       ['Artists2/Alexandre Jacques Chantron/Danae 18...\n",
       "43                                    ['Marc Chagall', '']\n",
       "61          ['Th√©odore G√©ricault', 'Eugene Delacroix', '']\n",
       "66       ['Tamara de Lempicka', 'Georg Pauli', 'Dorrit ...\n",
       "                               ...                        \n",
       "60232                            ['Harry Phelan Gibb', '']\n",
       "60235                          ['John Singer Sargent', '']\n",
       "60240    ['Paul √âmile Chabas', 'Alexandre-Jacques Chant...\n",
       "60261                                ['Kan≈ç Motonobu', '']\n",
       "60262                   ['Donatello', 'Paolo Uccello', '']\n",
       "Name: Pupils, Length: 1744, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artists_combined[artists_combined['Pupils'] != \"['Unknown']\"]['Pupils']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11       ['Jules Joseph Lefebvre', 'Gustave Boulanger',...\n",
       "32                               ['Aleksandra Ekster', '']\n",
       "40                      ['William-Adolphe Bouguereau', '']\n",
       "44            ['Anatol Petrytsky', 'Sergiy Grigoriev', '']\n",
       "45                                      ['Ilya Repin', '']\n",
       "                               ...                        \n",
       "60224                           ['Volodymyr Orlovsky', '']\n",
       "60240    ['Artists2/William Adolphe Bouguereau/Mother A...\n",
       "60247                          ['Jacques-Louis David', '']\n",
       "60257                        ['Mariotto Albertinelli', '']\n",
       "60495                                ['Fernand Leger', '']\n",
       "Name: Teachers, Length: 4015, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artists_combined[artists_combined['Teachers'] != \"['Unknown']\"]['Teachers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62                              ['Private Collection', '']\n",
       "156                                ['Gustave Courbet', '']\n",
       "169      ['Museo del Prado', ' Madrid', ' Spain', 'Muse...\n",
       "249      ['Louvre', ' Paris', ' France', 'Royal Collect...\n",
       "252                           ['Jean Lecomte du Nou√ø', '']\n",
       "                               ...                        \n",
       "60243    ['Edward Mitchell Bannister', 'Andres de Santa...\n",
       "60247                             ['Eugene Delacroix', '']\n",
       "60253                                ['132 x 96.1 cm', '']\n",
       "60257    ['Louvre', ' Paris', ' France', 'National Gall...\n",
       "60262                               ['Lorenzo Monaco', '']\n",
       "Name: Influencedon, Length: 10865, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artists_combined[artists_combined['Influencedon'] != \"['Unknown']\"]['Influencedon']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10       ['allegories-and-symbols', 'boats-and-ships', '']\n",
       "31       ['National Museum of Ancient Art (MNAA)', ' Li...\n",
       "34       ['Johannes Vermeer', 'Diego Velazquez', 'Claud...\n",
       "40                      ['William-Adolphe Bouguereau', '']\n",
       "44                                   ['Byzantine Art', '']\n",
       "                               ...                        \n",
       "60547                                 ['55 x 38.2 cm', '']\n",
       "60663                     ['Rene Magritte', 'Balthus', '']\n",
       "60664    ['El Greco', 'Francisco Goya', 'Rafael Zabalet...\n",
       "60680    ['battles-and-wars', 'Shinp≈´ren-Rebellion', '1...\n",
       "60683    ['actors-and-performances', 'male-portraits', ...\n",
       "Name: Influencedby, Length: 11264, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artists_combined[artists_combined['Influencedby'] != \"['Unknown']\"]['Influencedby']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10       ['Artists2/Mikalojus Ciurlionis/Wrath Ii 1904....\n",
       "11                                   ['Childe Hassam', '']\n",
       "32       ['Victor Palmov', 'David Burliuk', 'Oleksandr ...\n",
       "34       ['Edmund Charles Tarbell', 'Robert Lewis Reid'...\n",
       "45       ['Artists2/Anna Ostroumova Lebedeva/Self Portr...\n",
       "                               ...                        \n",
       "60421       ['Yves Klein', 'Heinz Mack', 'Otto Piene', '']\n",
       "60491                     ['Heinz Mack', 'Otto Piene', '']\n",
       "60664             ['Saturnino Herran', 'Diego Rivera', '']\n",
       "60680    ['Artists2/Tsukioka Yoshitoshi/Shinp Ren Rebel...\n",
       "60683    ['Artists2/Utagawa Kunisada/Not_Detected_24036...\n",
       "Name: FriendsandCoworkers, Length: 9374, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artists_combined[artists_combined['FriendsandCoworkers'] != \"['Unknown']\"]['FriendsandCoworkers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['artist', 'citizenship', 'gender', 'styles', 'movement',\n",
       "       'Art500k_Movements', 'birth_place', 'death_place', 'FirstYear',\n",
       "       'LastYear', 'wikiart_pictures_count', 'locations',\n",
       "       'locations_with_years', 'styles_extended', 'StylesCount', 'StylesYears',\n",
       "       'occupations', 'PaintingsExhibitedAt', 'PaintingsExhibitedAtCount',\n",
       "       'PaintingSchool', 'Influencedby', 'Influencedon', 'Pupils', 'Teachers',\n",
       "       'FriendsandCoworkers', 'Contemporary', 'Type', 'artist_name',\n",
       "       'Wikidata QID', 'DisplayName', 'Wiki QID', 'ULAN', 'Title', 'Artist',\n",
       "       'Date', 'Medium', 'Dimensions', 'CreditLine', 'AccessionNumber',\n",
       "       'Classification', 'Department', 'DateAcquired', 'Cataloged', 'ObjectID',\n",
       "       'URL', 'ImageURL', 'OnView', 'Circumference (cm)', 'Depth (cm)',\n",
       "       'Diameter (cm)', 'Height (cm)', 'Length (cm)', 'Weight (kg)',\n",
       "       'Width (cm)', 'Seat Height (cm)', 'Duration (sec.)', 'start_year',\n",
       "       'end_year', 'birth_year', 'death_year', 'Nationality', 'Gender',\n",
       "       'ArtistBio', 'ConstituentID', 'BeginDate', 'EndDate'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artists_combined.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 60713/60713 [00:27<00:00, 2227.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 127007 relationships between existing artists\n"
     ]
    }
   ],
   "source": [
    "cursor.execute(\"SELECT artist_name FROM Artists;\")\n",
    "existing_artists = set(cursor.fetchall())\n",
    "\n",
    "# Function to clean artist names\n",
    "def clean_artist_name(name):\n",
    "    # Remove path prefixes\n",
    "    name = re.sub(r'^Artists2/[^/]+/', '', name)\n",
    "    # Remove file extensions and suffixes\n",
    "    name = re.sub(r'/[^/]+\\s\\d{4}.*$', '', name)\n",
    "    name = re.sub(r'/Not_Detected_\\d+.*$', '', name)\n",
    "    return name.strip()\n",
    "\n",
    "# Parse relationship string into list of artist names\n",
    "def parse_relationship(relationship_str):\n",
    "    if pd.isna(relationship_str) or relationship_str == \"['Unknown']\":\n",
    "        return []\n",
    "    \n",
    "    try:\n",
    "        relationship_list = literal_eval(relationship_str)\n",
    "        artists = []\n",
    "        for item in relationship_list:\n",
    "            if item and not any([\n",
    "                item.startswith(('Louvre', 'Museo', 'National', 'Royal', 'Private')),\n",
    "                re.match(r'^\\d+\\s*x\\s*\\d+', item),\n",
    "                item.endswith(('cm', 'France', 'Spain')),\n",
    "                re.match(r'^[a-z\\-]+$', item)  # Lowercase with hyphens (tags)\n",
    "            ]):\n",
    "                artists.append(clean_artist_name(item))\n",
    "        return artists\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "# Process each row to extract relationships\n",
    "relationships = []\n",
    "\n",
    "for index, row in tqdm(artists_combined.iterrows(), total=artists_combined.shape[0]):\n",
    "    artist_name = row.get('artist', None)\n",
    "    \n",
    "    birth_year = row.get('birth_year', None)\n",
    "    if pd.isna(birth_year) or birth_year > 2030:\n",
    "        birth_year = None\n",
    "    birth_year = int(birth_year) if birth_year is not None else None\n",
    "    birth_year = None if birth_year == 0 else birth_year\n",
    "    \n",
    "    # Skip if this artist doesn't exist in the database\n",
    "    if (artist_name,) not in existing_artists:\n",
    "        continue\n",
    "    \n",
    "    # Process pupils\n",
    "    pupils = parse_relationship(row.get('Pupils'))\n",
    "    for pupil in pupils:\n",
    "        if (pupil,) in existing_artists:\n",
    "            relationships.append({\n",
    "                'artist1_name': artist_name,\n",
    "                'birth_year1': birth_year,\n",
    "                'artist2_name': pupil,\n",
    "                'relationship_type': 'Teacher'\n",
    "            })\n",
    "    \n",
    "    # Process teachers\n",
    "    teachers = parse_relationship(row.get('Teachers'))\n",
    "    for teacher in teachers:\n",
    "        if (teacher,) in existing_artists:\n",
    "            relationships.append({\n",
    "                'artist1_name': artist_name,\n",
    "                'birth_year1': birth_year,\n",
    "                'artist2_name': teacher,\n",
    "                'relationship_type': 'Pupil'\n",
    "            })\n",
    "    \n",
    "    # Process influences\n",
    "    influences = parse_relationship(row.get('Influencedby'))\n",
    "    for influence in influences:\n",
    "        if (influence,) in existing_artists:\n",
    "            relationships.append({\n",
    "                'artist1_name': artist_name,\n",
    "                'birth_year1': birth_year,\n",
    "                'artist2_name': influence,\n",
    "                'relationship_type': 'Influenced By'\n",
    "            })\n",
    "    \n",
    "    influenced = parse_relationship(row.get('Influencedon'))\n",
    "    for influence in influenced:\n",
    "        if (influence,) in existing_artists:\n",
    "            relationships.append({\n",
    "                'artist1_name': artist_name,\n",
    "                'birth_year1': birth_year,\n",
    "                'artist2_name': influence,\n",
    "                'relationship_type': 'Influenced On'\n",
    "            })\n",
    "    \n",
    "    # Process friends\n",
    "    friends = parse_relationship(row.get('FriendsandCoworkers'))\n",
    "    for friend in friends:\n",
    "        if (friend,) in existing_artists:\n",
    "            relationships.append({\n",
    "                'artist1_name': artist_name,\n",
    "                'birth_year1': birth_year,\n",
    "                'artist2_name': friend,\n",
    "                'relationship_type': 'Friend'\n",
    "            })\n",
    "\n",
    "# Write relationships to CSV file\n",
    "with open('clean_and_import_resources/artist_relationships.csv', \n",
    "          'w', newline='', encoding='utf-8') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['artist1_name', 'birth_year1', 'artist2_name', 'relationship_type'])\n",
    "    \n",
    "    for rel in relationships:\n",
    "        writer.writerow([\n",
    "            rel['artist1_name'],\n",
    "            rel['birth_year1'],\n",
    "            rel['artist2_name'],\n",
    "            rel['relationship_type']\n",
    "        ])\n",
    "\n",
    "print(f\"Processed {len(relationships)} relationships between existing artists\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Schools and Artist_Schools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# First, create and populate the PaintingSchools table\n",
    "painting_schools_data = artists_combined['PaintingSchool']\n",
    "\n",
    "# Create a set to store unique painting schools\n",
    "unique_schools = set()\n",
    "\n",
    "# Process each row in the PaintingSchool column with tqdm progress bar\n",
    "print(\"Extracting unique painting schools...\")\n",
    "for school in tqdm(painting_schools_data, desc=\"Processing schools\"):\n",
    "    if isinstance(school, str):  \n",
    "        # If it's a comma-separated string, split and strip spaces\n",
    "        unique_schools.update([sch.strip() for sch in school.split(', ') if sch.strip()])\n",
    "    elif isinstance(school, list):  \n",
    "        # If it's a list, clean each element\n",
    "        unique_schools.update([str(sch).strip() for sch in school if pd.notna(sch) and str(sch).strip()])\n",
    "    elif isinstance(school, np.ndarray):  \n",
    "        # Convert NumPy array to list and clean\n",
    "        if not pd.isna(school).all():  \n",
    "            unique_schools.update([str(sch).strip() for sch in school.tolist() if pd.notna(sch) and str(sch).strip()])\n",
    "    elif pd.notna(school):  \n",
    "        # Handle any other non-null value\n",
    "        unique_schools.add(str(school).strip())\n",
    "\n",
    "# Insert unique painting schools into the PaintingSchools table with tqdm progress bar\n",
    "print(\"Inserting unique painting schools into the Schools table...\")\n",
    "for school in tqdm(unique_schools, desc=\"Inserting schools\"):\n",
    "    try:\n",
    "        cursor.execute(\"\"\"\n",
    "            INSERT INTO Schools (school_name)\n",
    "            VALUES (%s)\n",
    "            ON CONFLICT (school_name) DO NOTHING;\n",
    "        \"\"\", (school,))\n",
    "    except Exception as e:\n",
    "        print(f\"Error inserting painting school {school} -> {e}\")\n",
    "        conn.rollback()\n",
    "\n",
    "# Now populate the Artist_PaintingSchools table\n",
    "artist_schools = []\n",
    "\n",
    "# Process the DataFrame to extract artist-school relationships\n",
    "print(\"Processing artist-painting school relationships...\")\n",
    "for index, row in tqdm(artists_combined.iterrows(), total=len(artists_combined), desc=\"Processing artists\"):\n",
    "    artist_name = row['artist_name']\n",
    "    birth_year = row['birth_year']\n",
    "    \n",
    "    # Get painting schools for this artist\n",
    "    schools = []\n",
    "    time_periods = {}\n",
    "    \n",
    "    # Check if we have a school_details column with structured data including time periods\n",
    "    if 'school_details' in row and pd.notna(row['school_details']):\n",
    "        # Assuming school_details is a dict or can be parsed as JSON with format:\n",
    "        # {school_name: {\"start_year\": year, \"end_year\": year}, ...}\n",
    "        if isinstance(row['school_details'], dict):\n",
    "            school_details = row['school_details']\n",
    "        elif isinstance(row['school_details'], str):\n",
    "            try:\n",
    "                school_details = json.loads(row['school_details'])\n",
    "            except:\n",
    "                school_details = {}\n",
    "        \n",
    "        for school_name, period in school_details.items():\n",
    "            if school_name.strip():\n",
    "                schools.append(school_name.strip())\n",
    "                time_periods[school_name.strip()] = period\n",
    "    \n",
    "    # If no structured data, extract schools from the PaintingSchool column\n",
    "    if not schools and 'PaintingSchool' in row and pd.notna(row['PaintingSchool']):\n",
    "        if isinstance(row['PaintingSchool'], str):\n",
    "            schools = [sch.strip() for sch in row['PaintingSchool'].split(', ') if sch.strip()]\n",
    "        elif isinstance(row['PaintingSchool'], list):\n",
    "            schools = [str(sch).strip() for sch in row['PaintingSchool'] if pd.notna(sch) and str(sch).strip()]\n",
    "        elif isinstance(row['PaintingSchool'], np.ndarray):\n",
    "            schools = [str(sch).strip() for sch in row['PaintingSchool'].tolist() if pd.notna(sch) and str(sch).strip()]\n",
    "        elif pd.notna(row['PaintingSchool']):\n",
    "            schools = [str(row['PaintingSchool']).strip()]\n",
    "    \n",
    "    # Add to our list of relationships to insert\n",
    "    for school in schools:\n",
    "        if school:\n",
    "            # Get time period for this school if available, or set to empty dict\n",
    "            period_json = time_periods.get(school, {})\n",
    "            \n",
    "            artist_schools.append({\n",
    "                'artist_name': artist_name,\n",
    "                'birth_year': birth_year,\n",
    "                'school_name': school,\n",
    "                'time_period': json.dumps(period_json) if period_json else None\n",
    "            })\n",
    "\n",
    "# Insert the artist-painting school relationships using executemany with psycopg2\n",
    "print(\"Inserting artist-painting school relationships...\")\n",
    "try:\n",
    "    cursor.executemany(\"\"\"\n",
    "        INSERT INTO Artist_Schools (artist_name, birth_year, school_name, time_period)\n",
    "        VALUES (%(artist_name)s, %(birth_year)s, %(school_name)s, %(time_period)s::jsonb)\n",
    "        ON CONFLICT (artist_name, birth_year, school_name) DO UPDATE \n",
    "        SET time_period = EXCLUDED.time_period;\n",
    "    \"\"\", artist_schools)\n",
    "    conn.commit()\n",
    "    print(f\"Successfully inserted {len(artist_schools)} artist-painting school relationships\")\n",
    "except Exception as e:\n",
    "    conn.rollback()\n",
    "    print(f\"Error batch inserting artist painting schools: {e}\")\n",
    "\n",
    "print(\"Artist Painting Schools Insertion Complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commit and close the connection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['artist', 'citizenship', 'gender', 'styles', 'movement', 'Art500k_Movements', 'birth_place', 'death_place', 'FirstYear', 'LastYear', 'wikiart_pictures_count', 'locations', 'locations_with_years', 'styles_extended', 'StylesCount', 'StylesYears', 'occupations', 'PaintingsExhibitedAt', 'PaintingsExhibitedAtCount', 'PaintingSchool', 'Influencedby', 'Influencedon', 'Pupils', 'Teachers', 'FriendsandCoworkers', 'Contemporary', 'Type', 'artist_name', 'Wikidata QID', 'DisplayName', 'Wiki QID', 'ULAN', 'Title', 'Artist', 'Date', 'Medium', 'Dimensions', 'CreditLine', 'AccessionNumber', 'Classification', 'Department', 'DateAcquired', 'Cataloged', 'ObjectID', 'URL', 'ImageURL', 'OnView', 'Circumference (cm)', 'Depth (cm)', 'Diameter (cm)', 'Height (cm)', 'Length (cm)', 'Weight (kg)', 'Width (cm)', 'Seat Height (cm)', 'Duration (sec.)', 'start_year', 'end_year', 'birth_year', 'death_year', 'Nationality', 'Gender', 'ArtistBio', 'ConstituentID', 'BeginDate', 'EndDate']\n"
     ]
    }
   ],
   "source": [
    "print(artists_combined.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Commit changes\n",
    "conn.commit()\n",
    "\n",
    "# Close the connection\n",
    "cursor.close()\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsc202project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
